{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import opendp.prelude as dp\n",
    "dp.enable_features(\"contrib\")\n",
    "dp.enable_features(\"floating-point\")\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters \n",
    "\n",
    "Choices of Mechanism are \n",
    "\n",
    "1. Laplace Mechanism (central & pure DP) denoted as \"laplace\"\n",
    "2. Stability Histogram (central & approximate DP) denoted as \"stabilityhist\"\n",
    "3. Unary Encoding (LDP) denoted as \"unaryencoding\"\n",
    "4. Randomised Response (LDP) denoted as \"randresponse\"\n",
    "5. Optimised Local Hashing (LDP) denoted as \"olh\"\n",
    "6. RAPPOR (LDP) denoted as \"rappor\"\n",
    "7. Hadamarrd Mechanism (LDP) denoted as \"hadamard\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Level: county or ed\n",
    "level = \"ed\"\n",
    "\n",
    "#Mechanism: laplace, stabilityhist, unaryencoding, randresponse, olh, hadamard, rappor\n",
    "#Mechanism = \"laplace\"\n",
    "#Mechanism_name = \"Laplace Mechanism\"\n",
    "\n",
    "Mechanism = \"randresponse\"\n",
    "\n",
    "#Path to data\n",
    "path = \"/Users/Ava/Library/CloudStorage/OneDrive-Personal/Thesis/Code/\"\n",
    "save = False\n",
    "\n",
    "max_influence = 2\n",
    "epsilon = np.arange(0.5,5.5, 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (level == \"county\" or level == \"ed\"):\n",
    "    raise Exception(f\"The level does not equal county or ed. The currrent input is {level=}\")\n",
    "\n",
    "\n",
    "if not (Mechanism == \"laplace\" or Mechanism == \"stabilityhist\" or Mechanism == \"unaryencoding\"  or Mechanism == \"randresponse\" or Mechanism == \"rappor\"  or Mechanism == \"olh\" or Mechanism == \"hadamard\"): \n",
    "    raise Exception(f\"The Mechanism is not supported or there is a typo with the input. Please check availiable Mechanisms are try again. /n  The current input is {Mechanism=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if level == \"county\":\n",
    "    Level = level.capitalize()\n",
    "if level == \"ed\":\n",
    "    Level = level.upper()\n",
    "\n",
    "#Outputs size=number of individuals, categories=list of all possible commutes, data_df = data where each row corresponds to an indidual, commutes = individuals commutes eg. commutes[1] = commute of individual 1 \n",
    "size, categories, col_names, data_df, commutes = get_variables(path, level, Level)\n",
    "\n",
    "if Mechanism == \"stabilityhist\":\n",
    "    delta = 1/(2*size)\n",
    "else:\n",
    "    delta = 0 \n",
    "\n",
    "budget = [(e, delta) for e in epsilon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sensitive Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "    data = input_data.read()\n",
    "    \n",
    "#This is the dataset without differential privacy. \n",
    "histogram = (\n",
    "    dp.t.make_split_dataframe(separator=\",\", col_names=col_names) >>\n",
    "    dp.t.make_select_column(key=f\"{Level}_commute\", TOA=str) >>\n",
    "    # Compute counts for each of the categories\n",
    "    dp.t.then_count_by_categories(categories=categories)\n",
    ")\n",
    "\n",
    "sensitive_counts = histogram(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "released_counts, elapsed_time, all_rmse = run_dp(Mechanism, col_names, Level, budget, max_influence, size, data, histogram, categories, commutes, sensitive_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save File for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_dataset_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "private_dataset_df['True Count'] =  sensitive_counts[:-1]\n",
    "for i, name in enumerate(budget):\n",
    "    private_dataset_df[f'Privacy {name[0]}'] = released_counts[i]\n",
    "\n",
    "if save:\n",
    "    private_dataset_df.to_csv(f'{level}_{Mechanism}_dp_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "    names = (\"epsilon, delta, rmse, elapsed_time\")\n",
    "    np.savetxt(f'rmse_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], all_rmse[i], elapsed_time[i]) for i in range(len(budget))] , header = names, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Commute level counts:\\n\", sensitive_counts[0:10])\n",
    "print(\"DP Commute level counts:\\n\", released_counts[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
