{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import opendp.prelude as dp\n",
    "dp.enable_features(\"contrib\")\n",
    "dp.enable_features(\"floating-point\")\n",
    "from utilities import * \n",
    "from pure_ldp.frequency_oracles import *\n",
    "from pure_ldp.heavy_hitters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StabilityHist import *\n",
    "from Laplace import *\n",
    "from Randomised_Response import *\n",
    "from Unary_Encoding import *\n",
    "from OLH import *\n",
    "from Hadamard import *\n",
    "from postprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Level: county or ed\n",
    "level = \"ed\"\n",
    "\n",
    "#Mechanism: laplace, stabilityhist, unaryencoding, randresponse, olh, hadamard, rappor\n",
    "#Mechanism = \"laplace\"\n",
    "#Mechanism_name = \"Laplace Mechanism\"\n",
    "\n",
    "Mechanism = \"randresponse\"\n",
    "\n",
    "#Path to data\n",
    "path = \"./\"\n",
    "save = True\n",
    "\n",
    "max_influence = 2\n",
    "epsilon = np.arange(0.5,5.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (level == \"county\" or level == \"ed\"):\n",
    "    raise Exception(f\"The level does not equal county or ed. The currrent input is {level=}\")\n",
    "\n",
    "\n",
    "if not (Mechanism == \"laplace\" or Mechanism == \"stabilityhist\" or Mechanism == \"unaryencoding\"  or Mechanism == \"randresponse\" or Mechanism == \"rappor\"  or Mechanism == \"olh\" or Mechanism == \"hadamard\"): \n",
    "    raise Exception(f\"The Mechanism is not supported or there is a typo with the input. Please check availiable Mechanisms are try again. /n  The current input is {Mechanism=}\")\n",
    "\n",
    "\n",
    "\n",
    "if level == \"county\":\n",
    "    Level = level.capitalize()\n",
    "if level == \"ed\":\n",
    "    Level = level.upper()\n",
    "\n",
    "def get_variables(path, level, Level):\n",
    "    agg_data_df = pd.read_csv(path + f\"Dagg_commute_{level}_level_all.csv\")\n",
    "    data_df = pd.read_csv(path + f\"Dcommute_{level}_level_all.csv\")\n",
    "\n",
    "    col_names = [f\"{Level}_commute\",f\"{Level}_Origin\",f\"{Level}_Destination\"]\n",
    "    size = len(data_df) #Number of individuals in dataset\n",
    "\n",
    "    categories = agg_data_df[f'{Level}_commute'].unique()\n",
    "    len(categories) # MUST TAKE FROM DATA WHERE CATEGORIES CAN HAVE COUNT 0 ie.not where each individual is row\n",
    "    categories = list(categories) #Number of possible categories \n",
    "\n",
    "    data_df.columns = col_names\n",
    "    commutes = data_df[f\"{Level}_commute\"].tolist()\n",
    "\n",
    "    return(size, categories, col_names, data_df, commutes)\n",
    "\n",
    "#Outputs size=number of individuals, categories=list of all possible commutes, data_df = data where each row corresponds to an indidual, commutes = individuals commutes eg. commutes[1] = commute of individual 1 \n",
    "size, categories, col_names, data_df, commutes = get_variables(path, level, Level)\n",
    "\n",
    "if Mechanism == \"stabilityhist\":\n",
    "    delta = 1/(2*size)\n",
    "else:\n",
    "    delta = 0 \n",
    "\n",
    "budget = [(e, delta) for e in epsilon]\n",
    "d = len(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Sensitive Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "    data_all = input_data.read()\n",
    "    \n",
    "#This is the dataset without differential privacy. \n",
    "histogram = (\n",
    "    dp.t.make_split_dataframe(separator=\",\", col_names=col_names) >>\n",
    "    dp.t.make_select_column(key=f\"{Level}_commute\", TOA=str) >>\n",
    "    # Compute counts for each of the categories\n",
    "    dp.t.then_count_by_categories(categories=categories)\n",
    ")\n",
    "\n",
    "sensitive_counts = histogram(data_all)\n",
    "sensitive_counts = sensitive_counts[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = dict((categories[i], i) for i in range(len(categories)))\n",
    "data = [datadict[commutes[i]] for i in range(len(commutes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26244"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Randomised Response with an epsilon value of  0.5\n",
      "Finished Randomised Response with an epsilon value of  0.5\n",
      "Starting Randomised Response with an epsilon value of  1.0\n",
      "Finished Randomised Response with an epsilon value of  1.0\n",
      "Starting Randomised Response with an epsilon value of  1.5\n",
      "Finished Randomised Response with an epsilon value of  1.5\n",
      "Starting Randomised Response with an epsilon value of  2.0\n",
      "Finished Randomised Response with an epsilon value of  2.0\n",
      "Starting Randomised Response with an epsilon value of  2.5\n",
      "Finished Randomised Response with an epsilon value of  2.5\n",
      "Starting Randomised Response with an epsilon value of  3.0\n",
      "Finished Randomised Response with an epsilon value of  3.0\n",
      "Starting Randomised Response with an epsilon value of  3.5\n",
      "Finished Randomised Response with an epsilon value of  3.5\n",
      "Starting Randomised Response with an epsilon value of  4.0\n",
      "Finished Randomised Response with an epsilon value of  4.0\n",
      "Starting Randomised Response with an epsilon value of  4.5\n",
      "Finished Randomised Response with an epsilon value of  4.5\n",
      "Starting Randomised Response with an epsilon value of  5.0\n",
      "Finished Randomised Response with an epsilon value of  5.0\n"
     ]
    }
   ],
   "source": [
    "if Mechanism == \"laplace\":\n",
    "   with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "      data = input_data.read()\n",
    "   released_counts, total_elapsed_time, all_rmse = Laplace_Mechamism(budget, max_influence, data, histogram, sensitive_counts)\n",
    "elif Mechanism == \"stabilityhist\":\n",
    "   with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "      data = input_data.read()\n",
    "   released_counts, total_elapsed_time, all_rmse =  Stability_Hist(col_names, Level, budget, max_influence, size, data, histogram, categories, sensitive_counts)\n",
    "elif Mechanism == \"randresponse\":\n",
    "   released_counts_client, elapsed_time_client = run_client(Mechanism, Level, budget, size, categories, commutes, sensitive_counts)\n",
    "   released_counts, elapsed_time_server = Randomised_Response_Server(released_counts_client, sensitive_counts,  size, budget, categories)\n",
    "   total_elapsed_time = [sum(element) for element in zip(elapsed_time_client, elapsed_time_server)]  \n",
    "elif Mechanism == \"unaryencoding\":\n",
    "   released_counts_client, elapsed_time_client = Unary_Encoding_Client(budget, size, categories, commutes, sensitive_counts)\n",
    "   released_counts, elapsed_time_server = Unary_Encoding_Server(released_counts_client, sensitive_counts,  size, budget)\n",
    "   total_elapsed_time = [sum(element) for element in zip(elapsed_time_client, elapsed_time_server)]\n",
    "elif Mechanism == \"olh\":\n",
    "   released_counts, total_elapsed_time = OLH(budget, data, d)\n",
    "elif Mechanism == \"hadamard\":\n",
    "   released_counts, total_elapsed_time = Hadamard(budget, data, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -13722.08779316, -135089.99989944,   26733.88290894,\n",
       "        -13722.08779316,  -54178.05849525,  107645.82431313,\n",
       "        107645.82431313,  107645.82431313,  188557.76571732])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "released_counts[0][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_counts, base_time, base_rmse = Base(released_counts, sensitive_counts, budget)\n",
    "base_pros_counts, base_pros_time, base_pros_rmse = Base_Pros(released_counts, sensitive_counts, budget)\n",
    "#base_cut_counts, base_cut_time, base_cut_rmse = Base_Cut(released_counts, sensitive_counts, budget, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1. Base\n",
    "# private_dataset1_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "# private_dataset1_df['True Count'] =  sensitive_counts\n",
    "# for i, name in enumerate(budget):\n",
    "#     private_dataset1_df[f'Privacy {name[0]}'] = base_counts[i]\n",
    "\n",
    "#2.Base Pro\n",
    "private_dataset2_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "private_dataset2_df['True Count'] =  sensitive_counts\n",
    "for i, name in enumerate(budget):\n",
    "    private_dataset2_df[f'Privacy {name[0]}'] = base_pros_counts[i]\n",
    "\n",
    "# #3.Base Cut\n",
    "# private_dataset3_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "# private_dataset3_df['True Count'] =  sensitive_counts\n",
    "# for i, name in enumerate(budget):\n",
    "#     private_dataset3_df[f'Privacy {name[0]}'] = base_cut_counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ED Level Commute</th>\n",
       "      <th>True Count</th>\n",
       "      <th>Privacy 0.5</th>\n",
       "      <th>Privacy 1.0</th>\n",
       "      <th>Privacy 1.5</th>\n",
       "      <th>Privacy 2.0</th>\n",
       "      <th>Privacy 2.5</th>\n",
       "      <th>Privacy 3.0</th>\n",
       "      <th>Privacy 3.5</th>\n",
       "      <th>Privacy 4.0</th>\n",
       "      <th>Privacy 4.5</th>\n",
       "      <th>Privacy 5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arran Quay A-Arran Quay A</td>\n",
       "      <td>1</td>\n",
       "      <td>229014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2293</td>\n",
       "      <td>0</td>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arran Quay A-Arran Quay B</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>55922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arran Quay A-Arran Quay C</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arran Quay A-Arran Quay D</td>\n",
       "      <td>1</td>\n",
       "      <td>26734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2723</td>\n",
       "      <td>1559</td>\n",
       "      <td>917</td>\n",
       "      <td>1367</td>\n",
       "      <td>1804</td>\n",
       "      <td>0</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arran Quay A-Arran Quay E</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3822</td>\n",
       "      <td>1314</td>\n",
       "      <td>204</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26239</th>\n",
       "      <td>Wood Quay B-Walkinstown A</td>\n",
       "      <td>4</td>\n",
       "      <td>67190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6255</td>\n",
       "      <td>7798</td>\n",
       "      <td>0</td>\n",
       "      <td>2295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26240</th>\n",
       "      <td>Wood Quay B-Walkinstown B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20066</td>\n",
       "      <td>0</td>\n",
       "      <td>1559</td>\n",
       "      <td>9174</td>\n",
       "      <td>549</td>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26241</th>\n",
       "      <td>Wood Quay B-Walkinstown C</td>\n",
       "      <td>2</td>\n",
       "      <td>107646</td>\n",
       "      <td>0</td>\n",
       "      <td>20066</td>\n",
       "      <td>6831</td>\n",
       "      <td>8603</td>\n",
       "      <td>2293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26242</th>\n",
       "      <td>Wood Quay B-Wood Quay A</td>\n",
       "      <td>22</td>\n",
       "      <td>26734</td>\n",
       "      <td>25373</td>\n",
       "      <td>4988</td>\n",
       "      <td>2723</td>\n",
       "      <td>6255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>Wood Quay B-Wood Quay B</td>\n",
       "      <td>22</td>\n",
       "      <td>188558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19157</td>\n",
       "      <td>0</td>\n",
       "      <td>2293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26244 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ED Level Commute  True Count  Privacy 0.5  Privacy 1.0  \\\n",
       "0      Arran Quay A-Arran Quay A           1       229014            0   \n",
       "1      Arran Quay A-Arran Quay B          17            0        55922   \n",
       "2      Arran Quay A-Arran Quay C           7            0            0   \n",
       "3      Arran Quay A-Arran Quay D           1        26734            0   \n",
       "4      Arran Quay A-Arran Quay E           0            0        86471   \n",
       "...                          ...         ...          ...          ...   \n",
       "26239  Wood Quay B-Walkinstown A           4        67190            0   \n",
       "26240  Wood Quay B-Walkinstown B           0            0            0   \n",
       "26241  Wood Quay B-Walkinstown C           2       107646            0   \n",
       "26242    Wood Quay B-Wood Quay A          22        26734        25373   \n",
       "26243    Wood Quay B-Wood Quay B          22       188558            0   \n",
       "\n",
       "       Privacy 1.5  Privacy 2.0  Privacy 2.5  Privacy 3.0  Privacy 3.5  \\\n",
       "0                0            0            0         2293            0   \n",
       "1                0            0            0         3670            0   \n",
       "2             4988            0            0            0            0   \n",
       "3                0         2723         1559          917         1367   \n",
       "4                0            0            0            0         3822   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "26239            0            0         6255         7798            0   \n",
       "26240        20066            0         1559         9174          549   \n",
       "26241        20066         6831         8603         2293            0   \n",
       "26242         4988         2723         6255            0            0   \n",
       "26243            0        19157            0         2293            0   \n",
       "\n",
       "       Privacy 4.0  Privacy 4.5  Privacy 5.0  \n",
       "0              823            0          306  \n",
       "1                0            0            0  \n",
       "2                0          204          127  \n",
       "3             1804            0         1022  \n",
       "4             1314          204          306  \n",
       "...            ...          ...          ...  \n",
       "26239         2295            0            0  \n",
       "26240         1314            0            0  \n",
       "26241            0            0            0  \n",
       "26242         2295            0            0  \n",
       "26243            0            0            0  \n",
       "\n",
       "[26244 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_dataset2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    private_dataset2_df.to_csv(f'Data/D_{level}_{Mechanism}_dp_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "    names = (\"epsilon, delta, rmse, total_elapsed_time, postprocessing_time\")\n",
    "    np.savetxt(f'Data/D_rmse_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], base_pros_rmse[i], total_elapsed_time[i], base_pros_time[i]) for i in range(len(budget))] , header = names, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save File for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save:\n",
    "#     private_dataset1_df.to_csv(f'Data/{level}_{Mechanism}_dp1_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "#     names = (\"epsilon, delta, rmse, total_elapsed_time, postprocessing_time\")\n",
    "#     np.savetxt(f'Data/rmse1_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], base_rmse[i], total_elapsed_time[i], base_time[i]) for i in range(len(budget))] , header = names, delimiter=',')\n",
    "\n",
    "#     private_dataset2_df.to_csv(f'Data/{level}_{Mechanism}_dp2_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "#     names = (\"epsilon, delta, rmse, total_elapsed_time, postprocessing_time\")\n",
    "#     np.savetxt(f'Data/rmse2_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], base_pros_rmse[i], total_elapsed_time[i], base_pros_time[i]) for i in range(len(budget))] , header = names, delimiter=',')\n",
    "\n",
    "#     private_dataset3_df.to_csv(f'Data/{level}_{Mechanism}_dp3_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "#     names = (\"epsilon, delta, rmse, total_elapsed_time, postprocessing_time\")\n",
    "#     np.savetxt(f'Data/rmse3_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], base_cut_rmse[i], total_elapsed_time[i], base_cut_time[i]) for i in range(len(budget))] , header = names, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OLH with an epsilon value of  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ava/opt/anaconda3/lib/python3.9/site-packages/pure_ldp/core/_freq_oracle_server.py:76: RuntimeWarning: High privacy has been detected (epsilon = 0.5), estimations may be highly inaccurate on small datasets\n",
      "  warnings.warn(\"High privacy has been detected (epsilon = \" + str(self.epsilon) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished OLH with an epsilon value of  0.5\n",
      "Starting OLH with an epsilon value of  1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m    total_elapsed_time \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(element) \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(elapsed_time_client, elapsed_time_server)]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Mechanism \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molh\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m    released_counts, total_elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mOLH\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Mechanism \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhadamard\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     81\u001b[0m    released_counts, total_elapsed_time \u001b[38;5;241m=\u001b[39m Hadamard(budget, data, d)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Thesis/Code/OLH.py:22\u001b[0m, in \u001b[0;36mOLH\u001b[0;34m(budget, data, d)\u001b[0m\n\u001b[1;32m     19\u001b[0m     priv_data \u001b[38;5;241m=\u001b[39m client_olh\u001b[38;5;241m.\u001b[39mprivatise(item)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Simulate server-side aggregation\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mserver_olh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpriv_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     26\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pure_ldp/frequency_oracles/local_hashing/lh_server.py:60\u001b[0m, in \u001b[0;36mLHServer.aggregate\u001b[0;34m(self, priv_data)\u001b[0m\n\u001b[1;32m     57\u001b[0m priv_data \u001b[38;5;241m=\u001b[39m priv_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpriv_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxxhash\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxxh32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintdigest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregated_data[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Level: county or ed\n",
    "level = \"ed\"\n",
    "\n",
    "#Mechanism: laplace, stabilityhist, unaryencoding, randresponse, olh, hadamard, rappor\n",
    "#Mechanism = \"laplace\"\n",
    "#Mechanism_name = \"Laplace Mechanism\"\n",
    "\n",
    "Mechanism = \"olh\"\n",
    "\n",
    "#Path to data\n",
    "path = \"./\"\n",
    "save = True\n",
    "\n",
    "max_influence = 2\n",
    "epsilon = np.arange(0.5,5.5, 0.5)\n",
    "\n",
    "if not (level == \"county\" or level == \"ed\"):\n",
    "    raise Exception(f\"The level does not equal county or ed. The currrent input is {level=}\")\n",
    "\n",
    "\n",
    "if not (Mechanism == \"laplace\" or Mechanism == \"stabilityhist\" or Mechanism == \"unaryencoding\"  or Mechanism == \"randresponse\" or Mechanism == \"rappor\"  or Mechanism == \"olh\" or Mechanism == \"hadamard\"): \n",
    "    raise Exception(f\"The Mechanism is not supported or there is a typo with the input. Please check availiable Mechanisms are try again. /n  The current input is {Mechanism=}\")\n",
    "\n",
    "\n",
    "\n",
    "if level == \"county\":\n",
    "    Level = level.capitalize()\n",
    "if level == \"ed\":\n",
    "    Level = level.upper()\n",
    "\n",
    "\n",
    "\n",
    "#Outputs size=number of individuals, categories=list of all possible commutes, data_df = data where each row corresponds to an indidual, commutes = individuals commutes eg. commutes[1] = commute of individual 1 \n",
    "size, categories, col_names, data_df, commutes = get_variables(path, level, Level)\n",
    "\n",
    "if Mechanism == \"stabilityhist\":\n",
    "    delta = 1/(2*size)\n",
    "else:\n",
    "    delta = 0 \n",
    "\n",
    "budget = [(e, delta) for e in epsilon]\n",
    "d = len(categories)\n",
    "\n",
    "with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "    data_all = input_data.read()\n",
    "    \n",
    "#This is the dataset without differential privacy. \n",
    "histogram = (\n",
    "    dp.t.make_split_dataframe(separator=\",\", col_names=col_names) >>\n",
    "    dp.t.make_select_column(key=f\"{Level}_commute\", TOA=str) >>\n",
    "    # Compute counts for each of the categories\n",
    "    dp.t.then_count_by_categories(categories=categories)\n",
    ")\n",
    "\n",
    "sensitive_counts = histogram(data_all)\n",
    "sensitive_counts = sensitive_counts[:-1]\n",
    "\n",
    "\n",
    "datadict = dict((categories[i], i) for i in range(len(categories)))\n",
    "data = [datadict[commutes[i]] for i in range(len(commutes))]\n",
    "\n",
    "if Mechanism == \"laplace\":\n",
    "   with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "      data = input_data.read()\n",
    "   released_counts, total_elapsed_time, all_rmse = Laplace_Mechamism(budget, max_influence, data, histogram, sensitive_counts)\n",
    "elif Mechanism == \"stabilityhist\":\n",
    "   with open(f'commute_{level}_level_all.csv') as input_data:\n",
    "      data = input_data.read()\n",
    "   released_counts, total_elapsed_time, all_rmse =  Stability_Hist(col_names, Level, budget, max_influence, size, data, histogram, categories, sensitive_counts)\n",
    "elif Mechanism == \"randresponse\":\n",
    "   released_counts_client, elapsed_time_client = run_client(Mechanism, Level, budget, size, categories, commutes, sensitive_counts)\n",
    "   released_counts, elapsed_time_server = Randomised_Response_Server(released_counts_client, sensitive_counts,  size, budget, categories)\n",
    "   total_elapsed_time = [sum(element) for element in zip(elapsed_time_client, elapsed_time_server)]  \n",
    "elif Mechanism == \"unaryencoding\":\n",
    "   released_counts_client, elapsed_time_client = Unary_Encoding_Client(budget, size, categories, commutes, sensitive_counts)\n",
    "   released_counts, elapsed_time_server = Unary_Encoding_Server(released_counts_client, sensitive_counts,  size, budget)\n",
    "   total_elapsed_time = [sum(element) for element in zip(elapsed_time_client, elapsed_time_server)]\n",
    "elif Mechanism == \"olh\":\n",
    "   released_counts, total_elapsed_time = OLH(budget, data, d)\n",
    "elif Mechanism == \"hadamard\":\n",
    "   released_counts, total_elapsed_time = Hadamard(budget, data, d)\n",
    "\n",
    "#base_counts, base_time, base_rmse = Base(released_counts, sensitive_counts, budget)\n",
    "base_pros_counts, base_pros_time, base_pros_rmse = Base_Pros(released_counts, sensitive_counts, budget)\n",
    "#base_cut_counts, base_cut_time, base_cut_rmse = Base_Cut(released_counts, sensitive_counts, budget, size)\n",
    "\n",
    "# #1. Base\n",
    "# private_dataset1_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "# private_dataset1_df['True Count'] =  sensitive_counts\n",
    "# for i, name in enumerate(budget):\n",
    "#     private_dataset1_df[f'Privacy {name[0]}'] = base_counts[i]\n",
    "\n",
    "#2.Base Pro\n",
    "private_dataset2_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "private_dataset2_df['True Count'] =  sensitive_counts\n",
    "for i, name in enumerate(budget):\n",
    "    private_dataset2_df[f'Privacy {name[0]}'] = base_pros_counts[i]\n",
    "\n",
    "# #3.Base Cut\n",
    "# private_dataset3_df = pd.DataFrame(categories, columns = [f'{Level} Level Commute'])\n",
    "# private_dataset3_df['True Count'] =  sensitive_counts\n",
    "# for i, name in enumerate(budget):\n",
    "#     private_dataset3_df[f'Privacy {name[0]}'] = base_cut_counts[i]\n",
    "\n",
    "\n",
    "if save:\n",
    "    private_dataset2_df.to_csv(f'Data/D_{level}_{Mechanism}_dp_df.csv', sep=',', index=False, encoding='utf-8', mode='w')\n",
    "    names = (\"epsilon, delta, rmse, total_elapsed_time, postprocessing_time\")\n",
    "    np.savetxt(f'Data/D_rmse_{Mechanism}_{Level}.csv', [(budget[i][0], budget[i][1], base_pros_rmse[i], total_elapsed_time[i], base_pros_time[i]) for i in range(len(budget))] , header = names, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
